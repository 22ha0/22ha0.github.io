
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>【论文笔记&amp;总结】（AlexNet）ImageNet Classification with Deep Convolutional Neural Networks - ZZH&#39;s NoteBook</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="TriDiamond Obsidian,"> 
    <meta name="description" content="Abstract​		摘要部分介绍了AlexNet参加ImageNet LSVRC-2010 比赛，将120万张图片分成1000类，在top1和top5中错误率为37.5%和17.0%，超越了之前的,"> 
    <meta name="author" content="ZZH"> 
    <link rel="alternative" href="atom.xml" title="ZZH&#39;s NoteBook" type="application/atom+xml"> 
    <link rel="icon" href="/img/dog.jpg"> 
    
<link rel="stylesheet" href="//at.alicdn.com/t/font_1429596_nzgqgvnmkjb.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.7.2/animate.min.css">

    
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/codemirror.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/theme/dracula.css">

    
<link rel="stylesheet" href="/css/obsidian.css">

    
<link rel="stylesheet" href="/css/ball-atom.min.css">

    
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">

    
    <script>var musiclist = ""</script>
    
<script src="/js/loadaplayer.js"></script>

    <!-- 引用依赖 -->
    
<link rel="stylesheet" href="/aplayer/dist/APlayer.min.css">

    
<script src="/aplayer/dist/APlayer.min.js"></script>
<script src="/js/Meting.min.js"></script>

    
<meta name="generator" content="Hexo 6.3.0"></head>


<body class="loading">
    <div class="loader">
        <div class="la-ball-atom la-2x">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
    <span id="config-title" style="display:none">ZZH&#39;s NoteBook</span>
    <div id="loader"></div>
    <div id="single">
    <div class="scrollbar gradient-bg-rev"></div>
<div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <div class="navigation animated fadeIn fast delay-1s">
        <img id="home-icon" class="icon-home" src="/img/dog.jpg" alt="" data-url="http://example.com">
        <div id="play-icon" title="Play/Pause" class="iconfont icon-play"></div>
        <h3 class="subtitle">【论文笔记&总结】（AlexNet）ImageNet Classification with Deep Convolutional Neural Networks</h3>
        <div class="social">
            <!--        <div class="like-icon">-->
            <!--            <a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
            <!--        </div>-->
            <div>
                <div class="share">
                    
                        <a href="javascript:;" class="iconfont icon-share1"></a>
                        <div class="share-component-cc" data-disabled="facebook,douban,linkedin,diandian,tencent,google"></div>
                    
                </div>
            </div>
        </div>
    </div>
</div>

    <div class="section">
        <div class=article-header-wrapper>
    <div class="article-header">
        <div class="article-cover animated fadeIn" style="
            animation-delay: 600ms;
            animation-duration: 1.2s;
            background-image: 
                radial-gradient(ellipse closest-side, rgba(0, 0, 0, 0.65), #100e17),
                url('https://22ha0.github.io/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701154719693.png') ">
        </div>
        <div class="else">
            <p class="animated fadeInDown">
                
                <a href="/categories/论文总结&笔记"><b>「
                    </b>论文总结&笔记<b> 」</b></a>
                
                July 01, 2023
            </p>
            <h3 class="post-title animated fadeInDown"><a href="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/" title="【论文笔记&amp;总结】（AlexNet）ImageNet Classification with Deep Convolutional Neural Networks" class="">【论文笔记&amp;总结】（AlexNet）ImageNet Classification with Deep Convolutional Neural Networks</a>
            </h3>
            
            <p class="post-count animated fadeInDown">
                
                <span>
                    <b class="iconfont icon-text2"></b> <i>Words count</i>
                    9.7k
                </span>
                
                
                <span>
                    <b class="iconfont icon-timer__s"></b> <i>Reading time</i>
                    9 mins.
                </span>
                
                
                
                <span id="busuanzi_container_page_pv">
                    <b class="iconfont icon-read"></b> <i>Read count</i>
                    <span id="busuanzi_value_page_pv">0</span>
                </span>
                
            </p>
            
            
            <ul class="animated fadeInDown post-tags-list" itemprop="keywords"><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/AlexNet/" rel="tag">AlexNet</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Deep-Learn/" rel="tag">Deep Learn</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/" rel="tag">图像识别</a></li></ul>
            
        </div>
    </div>
</div>

<div class="screen-gradient-after">
    <div class="screen-gradient-content">
        <div class="screen-gradient-content-inside">
            <div class="bold-underline-links screen-gradient-sponsor">
                <p>
                    <span class="animated fadeIn delay-1s"></span>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="article">
    <div class='main'>
        <div class="content markdown animated fadeIn">
            <h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>​		摘要部分介绍了AlexNet参加ImageNet LSVRC-2010 比赛，将120万张图片分成1000类，在top1和top5中错误率为37.5%和17.0%，超越了之前的其他技术。在AlexNet中有6000万个参数和650,000个神经元。为了加快训练的速度使用了不饱和神经元和高效的GPU进行卷积操作。为了减少全连接层过拟合使用了dropout方法。这个模型在ILSVRC-2012比赛中top-5的错误率为15.3%，比第二名的26.2%更好。</p>
<h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><ol>
<li><p>要训练更强大的模型需要使用更大的数据集和更强的模型，并且用更好的技术减少过拟合。</p>
</li>
<li><p>对于数据量较小的数据集可以使用“标签-保存转换”进行数据增强</p>
</li>
<li><p>CNN效果可以通过深度和宽度进行控制，与具有相似大小层的前馈神经网络相比，CNN的连接和参数要少得多，因此它们更容易训练，而理论上的最佳性能可能只是稍微差一些。</p>
</li>
<li><p>在第四部分会讲解减少过拟合的方法</p>
</li>
<li><p>最终网络包含了5个卷积层和3个全连接层，但是去掉任何一层的卷积层，性能都会变差。（强调深度的重要性）</p>
</li>
<li><p>本文使用了两条GTX580 3GB GPU进行训练，训练了5-6天的时间。</p>
</li>
</ol>
<h1 id="2-The-Dataset"><a href="#2-The-Dataset" class="headerlink" title="2 The Dataset"></a>2 The Dataset</h1><p>ImageNet是一个包含超过1500万张被标记的高分辨率图像的数据集，大约有22,000个类别。</p>
<p>ILSVRC使用了ImageNet的一个子集，在1000个类别中，每个类别中有大约1000张图像。总共，大约有120万张训练图像，5万张验证图像和15万张测试图像。</p>
<p>ImageNet由各种分辨率的图像组成，而我们的系统需要一个恒定的输入维数。因此，我们将图像进行降采样到256×256的固定分辨率。首先重新将图像缩放，使较短的一侧长度为256，然后从结果图像中裁剪出中间256×256的图像。</p>
<p>除了在训练集上对像素减去平均活跃度（mean activity）外,没有进行其他的预处理，我们根使用原始RGB值来训练我们的网络。</p>
<h1 id="3-The-Architecture"><a href="#3-The-Architecture" class="headerlink" title="3 The Architecture"></a>3 The Architecture</h1><img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701170713367.png" class title="image-20230701170713367">

<p>如图，AlexNet的网络架构包含8层——5个卷积层和3个全连接层。从上面的图我们可以看出有两个卷积的操作，一个在上面，一个在下面，其实想表达的是在实际操作中，一个GPU运行图中上面部分的层，而另一个GPU运行图下面部分的层。两个GPU只在特定的层进行交流。（从图上看，我猜是在FC处共享参数），网络的输入是150,528维(224 * 224 * 3，这里就有点迷，明明图像预处理是弄成 256 * 256 * 3  ，这里怎么就成了224了)，网络剩下层的神经元数目分别是253,440 -&gt; 186,624 -&gt; 64,896 -&gt;  64,896 -&gt; 43,264 -&gt; 4096 -&gt; 4096 -&gt; 1000。</p>
<h2 id="3-1ReLU-Nonlinearity"><a href="#3-1ReLU-Nonlinearity" class="headerlink" title="3.1ReLU Nonlinearity"></a>3.1<strong>ReLU Nonlinearity</strong></h2><p>ReLU <em>f</em>(<em>x</em>) &#x3D; max(0*, x*) 为非饱和激活函数</p>
<p>在梯度下降的训练时间方面，这些饱和非线性比非饱和非线性要慢得多。具有ReLUs的深度卷积神经网络的训练速度比具有其他单位的同类神经网络快几倍。</p>
<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701171510101.png" class title="image-20230701171510101">A four-layer convolutional neuralnetwork with ReLUs **(solid line)** reaches a 25%training error rate on CIFAR-10 six times fasterthan an equivalent network with tanh neurons**(dashed line)**.

<p>图中显示了在一个特定的四层卷积网络的CIFAR-10数据集上达到25%的训练误差所需的迭代次数。这幅图表明，如果使用传统的饱和神经元模型，我们就不可能用如此大型的神经网络进行实验。</p>
<h2 id="3-2-Training-on-Multiple-GPUs"><a href="#3-2-Training-on-Multiple-GPUs" class="headerlink" title="3.2 Training on Multiple GPUs"></a><strong>3.2 Training on Multiple GPUs</strong></h2><p>（偏工程细节，非机器学习重点，略）</p>
<h2 id="3-3-Local-Response-Normalization"><a href="#3-3-Local-Response-Normalization" class="headerlink" title="3.3 Local Response Normalization"></a><strong>3.3 Local Response Normalization</strong></h2><p> 局部响应归一化方法</p>
<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701172739424.png" class title="image-20230701172739424">

<p>其中，和在n个“相邻的”核映射上运行，N是该层中的核总数。核映射的顺序当然是任意的，并且在训练开始之前就已经确定了。这种反应标准化实现了一种侧抑制形式，灵感来自于在真实神经元中发现的类型，在使用不同内核计算的神经元输出之间创造了对大活动的竞争。常数k、n、α和β是超参数，其值通过验证集确定，使用了k&#x3D;2，n&#x3D;5，α&#x3D;10−4和β &#x3D; 0.75。</p>
<p>局部归一化的作用是分别减少了top-1 1.4%，top-5 1.2%的错误率。我们也在CIFAR-10数据集上验证了这个方案的有效性：没有归一化的四层CNN取得了13%的错误率，而使用归一化取得了11%的错误率。</p>
<h2 id="3-4-Overlapping-Pooling"><a href="#3-4-Overlapping-Pooling" class="headerlink" title="3.4 Overlapping Pooling"></a><strong>3.4 Overlapping Pooling</strong></h2><p>重叠池化和普通池化不同的地方就是，重叠池化的步长比核的长和宽都要小，这样就会导致下一步的池化的像素点和上一步的池化的像素点有重叠，故称为重叠池化。  网格间距为s个像素，这里的s就是step，每个网格归纳池化单元中心位置z × z大小的邻居。如果设置s &#x3D; z，我们会得到通常在CNN中采用的传统局部池化。如果设置s &lt;  z，就会得到重叠池化。这就是AlexNet网络中使用的方法，设置s &#x3D; 2，z &#x3D; 3。</p>
<p>这个方案与非重叠方案s &#x3D; 2, z &#x3D;  2相比，分别降低了top-1 0.4%，top-5  0.3%的错误率，两者的输出维度是相等的。我们在训练过程发现，采用重叠池化的模型更难以过拟合。</p>
<h2 id="3-5-Overall-Architecture"><a href="#3-5-Overall-Architecture" class="headerlink" title="3.5 Overall Architecture"></a><strong>3.5 Overall Architecture</strong></h2><p>AlexNet包含八层权重；前五个是卷积的，其余三个是完全连接的。最后一个完全连接层的输出被输入到一个1000路的softmax，它产生一个超过1000个类标签的分布。</p>
<p>第四和第五个卷积层的内核只连接到位于同一个GPU上的上一层中的内核映射.第三个卷积层的内核连接到第二个层的所有内核映射。完全连接的层中的神经元与前一层中的所有神经元相连。响应归一化层遵循第一层和第二层卷积层。在第3.4节中描述的最大池化层，同时遵循响应标准化层和第五个卷积层。ReLU非线性应用于每个卷积层和全连接层的输出。</p>
<p>第一个卷积层用96个大小为11×11×3的核对224×224×3的输入图像进行过滤，跨度为4像素（这是核图中相邻神经元的感受野中心的距离）。第二个卷积层将第一个卷积层的输出（响应归一化和集合化）作为输入，并用256个大小为5×5×48的核对其进行过滤。第三、第四和第五卷积层相互连接，没有任何中间的池化或规范化层。第三卷积层有384个大小为3×3×256的核，与第二卷积层的（归一化、池化的）输出相连。第四卷积层有384个大小为3×3×192的核，第五卷积层有256个大小为3×3×192的核。核，大小为3×3×192。全连接层每个有4096个神经元。</p>
<p>第八层是再连接到一个大小为1000的全连接层中，用softmax，来算1000种分类的分布。</p>
<h1 id="4-Reducing-Overfifitting"><a href="#4-Reducing-Overfifitting" class="headerlink" title="4 Reducing Overfifitting"></a><strong>4 Reducing Overfifitting</strong></h1><p>由于神经网络的结构存在6千万个参数 尽管ILSVRC的1000类使每个训练样本从图像到标签的映射上强加了10比特的约束，但这不足以学习这么多的参数而没有相当大的过拟合。 它使用了两种方式来避免过拟合。</p>
<h2 id="4-1-Data-Augmentation"><a href="#4-1-Data-Augmentation" class="headerlink" title="4.1 Data Augmentation"></a><strong>4.1 Data Augmentation</strong></h2><p>第一种数据增强方式包括产生图像平移和水平翻转。我们从256× 256图像上通过随机提取224 ×  224的图像块（以及这些图像块的水平翻转）实现了这种方式，然后在这些提取的图像块上进行训练，最终的训练样本是高度相关的。没有这个方案，我们的网络会有大量的过拟合，这会迫使我们使用更小的网络。在测试时，网络会提取5个224 ×  224的图像块（四个角上的图像块和中心的图像块）和它们的水平翻转（因此总共10个图像块）进行预测，然后对网络在10个图像块上的softmax层的预测结果进行平均。</p>
<p>第二种数据增强方式包括改变训练图像的RGB通道的强度。具体地，我们在整个ImageNet训练集上对RGB像素值集合（一个pixel有三个值RGB也就是（224 × 224）× 3 这么大的矩阵，224  × 224是行数，3是列数），执行主成分分析（PCA）。对于每幅训练图像，我们这个大矩阵的主成分，大小成正比的对应特征值乘以一个随机变量，随机变量通过均值为0，标准差为0.1的高斯分布得到。</p>
<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701175729787.png" class title="image-20230701175729787">

<h2 id="4-2-Dropout"><a href="#4-2-Dropout" class="headerlink" title="4.2 Dropout"></a><strong>4.2 Dropout</strong></h2><p>Dropout，它会以0.5的概率对每个隐层神经元的输出设为0。那些用这种方式“丢弃”的神经元不再进行前向传播并且不参与反向传播。因此每次输入时，神经网络会采样一个不同的架构，但所有架构共享权重。这个技术减少了复杂的神经元互适应，因为一个神经元不能依赖特定的其它神经元的存在。因此，神经元被强迫学习更鲁棒的特征，这让它在与许多不同层的神经元的连接时更为有效。在测试时，我们使用所有的神经元但它们的输出乘以0.5，这是对指数级的dropout网络的预测分布的几何平均一种合理的估计。</p>
<h1 id="5-Details-of-learning"><a href="#5-Details-of-learning" class="headerlink" title="5    Details of learning"></a>5    Details of learning</h1><p>我们使用随机梯度下降来训练我们的模型，批量大小为128个例子，动量为0.9，权重衰减为0.0005。我们发现，这少量的重量衰减对模型的学习很重要。换句话说，这里的权重衰减不仅仅是一个正则化器：它减少了模型的训练误差。重量<em>w</em>的更新规则为</p>
<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701174808461.png" class title="image-20230701174808461">

<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701174845338.png" class title="image-20230701174845338">

<p>我们使用均值为0，标准差为0.01的高斯分布对每一层的权重进行初始化。我们在第2，4，5卷积层和全连接隐层将神经元偏置初始化为常量1。这个初始化通过为ReLU提供正输入加速了早期阶段的学习。我们对剩下的层的神经元偏置初始化为0。</p>
<p>我们对所有的层使用相等的学习率，这个是在整个训练过程中我们手动调整得到的。当验证误差在当前的学习率下停止改善时，我们遵循启发式的方法将学习率除以10。学习率初始化为0.01，在训练停止之前降低三次。我们在120万图像的训练数据集上训练神经网络大约90个循环，在两个NVIDIA GTX 580 3GB GPU上花费了五到六天。</p>
<h1 id="6-Results"><a href="#6-Results" class="headerlink" title="6 Results"></a><strong>6 Results</strong></h1><img src="undefined2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701174550292.png" alt="image-20230701174550292" style="zoom:50%;">

<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701174602623.png" class title="image-20230701174602623">

<h2 id="6-1-Qualitative-Evaluations"><a href="#6-1-Qualitative-Evaluations" class="headerlink" title="6.1 Qualitative Evaluations"></a><strong>6.1 Qualitative Evaluations</strong></h2><img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701174638350.png" class title="image-20230701174638350">

<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><strong>论文原文：</strong><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf</a></p>
<p><strong>参考文章：</strong></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/80087776">https://zhuanlan.zhihu.com/p/80087776</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35547281/article/details/96108319">https://blog.csdn.net/qq_35547281/article/details/96108319</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/d42z/p/16788621.html">https://www.cnblogs.com/d42z/p/16788621.html</a></p>
<h1 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h1><h2 id="非饱和神经元（non-saturating-neurons）"><a href="#非饱和神经元（non-saturating-neurons）" class="headerlink" title="非饱和神经元（non-saturating neurons）"></a>非饱和神经元（non-saturating neurons）</h2><p>参考链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zeronose/article/details/108939613">https://blog.csdn.net/zeronose/article/details/108939613</a></p>
<p><strong>含义</strong><br>non-saturating neurons &#x3D; 没有被挤压（到一个特定的区间）处理过的值</p>
<p>saturating neurons &#x3D; 被挤压（到一个特定的区间）过的值<br> <em><strong>关键:1.值是否被挤压 2.值有无最大最小限制</strong></em></p>
<p>输出saturating neurons的activation：<br> sigmoid: input neurons的值会被挤压到[0,1]的区间</p>
<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701175247186.png" class title="image-20230701175247186">

<p>anh：input neurons的值会被挤压到[-1,1]的区间</p>
<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701175331841.png" class title="image-20230701175331841">

<p>输出non-saturating neurons 的activation：<br>relu：input neurons的值，要么变0， 要么保持原值（无挤压，无最大最小值限制）</p>
<img src="/2023/07/01/alexnet%E8%AE%BA%E6%96%87/image-20230701175338432.png" class title="image-20230701175338432">

<p>leaky_relu：input neurons的值， 要么按照某比例缩小，要么保持原值（无挤压，无最大最小值限制）<br>在这里插入图片描述</p>
<p>为什么要用relu这样的能生成non-saturating neurons的non-linear activations, 而不用生成saturating neurons的sigmoid或tanh?<br>规避vanishing, exploding of gradients 带来的gradient值过大过小，导致训练效率低下。</p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls"
                data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
            <ul id="audio-list" style="display:none">
                
            </ul>
            
                        
            
            
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d=''
        data-p='https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token'
    >Comments</div>


            
            
        </div>
        <div class="sidebar">
            <div class="box animated fadeInRight">
                <div class="subbox">
                    <img src="/img/dog.jpg" height=300 width=300></img>
                    <p>ZZH</p>
                    <span>Think like an artist, develop like an artisan</span>
                    <dl>
                        
                        
                    </dl>
                </div>
                <ul>
                    <li><a href="/">20 <p>Articles</p></a></li>
                    <li><a href="/categories">2 <p>Categories</p></a></li>
                    <li><a href="/tags">28 <p>Tags</p></a></li>
                </ul>
            </div>
            
            
            
            <div class="box sticky animated fadeInRight faster">
                <div id="toc" class="subbox">
                    <h4>Contents</h4>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-introduction"><span class="toc-number">2.</span> <span class="toc-text">1 introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-The-Dataset"><span class="toc-number">3.</span> <span class="toc-text">2 The Dataset</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-The-Architecture"><span class="toc-number">4.</span> <span class="toc-text">3 The Architecture</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1ReLU-Nonlinearity"><span class="toc-number">4.1.</span> <span class="toc-text">3.1ReLU Nonlinearity</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-Training-on-Multiple-GPUs"><span class="toc-number">4.2.</span> <span class="toc-text">3.2 Training on Multiple GPUs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-Local-Response-Normalization"><span class="toc-number">4.3.</span> <span class="toc-text">3.3 Local Response Normalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-Overlapping-Pooling"><span class="toc-number">4.4.</span> <span class="toc-text">3.4 Overlapping Pooling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5-Overall-Architecture"><span class="toc-number">4.5.</span> <span class="toc-text">3.5 Overall Architecture</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Reducing-Overfifitting"><span class="toc-number">5.</span> <span class="toc-text">4 Reducing Overfifitting</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-Data-Augmentation"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 Data Augmentation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-Dropout"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 Dropout</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Details-of-learning"><span class="toc-number">6.</span> <span class="toc-text">5    Details of learning</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-Results"><span class="toc-number">7.</span> <span class="toc-text">6 Results</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-Qualitative-Evaluations"><span class="toc-number">7.1.</span> <span class="toc-text">6.1 Qualitative Evaluations</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Reference"><span class="toc-number">8.</span> <span class="toc-text">Reference</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Other"><span class="toc-number">9.</span> <span class="toc-text">Other</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E9%A5%B1%E5%92%8C%E7%A5%9E%E7%BB%8F%E5%85%83%EF%BC%88non-saturating-neurons%EF%BC%89"><span class="toc-number">9.1.</span> <span class="toc-text">非饱和神经元（non-saturating neurons）</span></a></li></ol></li></ol>
                </div>
            </div>
            
            
        </div>
    </div>
</div>

    </div>
</div>
    <div id="back-to-top" class="animated fadeIn faster">
        <div class="flow"></div>
        <span class="percentage animated fadeIn faster">0%</span>
        <span class="iconfont icon-top02 animated fadeIn faster"></span>
    </div>
</body>
<footer>
    <p class="copyright" id="copyright">
        &copy; 2023
        <span class="gradient-text">
            ZZH
        </span>.
        Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
        Theme
        <span class="gradient-text">
            <a href="https://github.com/TriDiamond/hexo-theme-obsidian" title="Obsidian" target="_blank" rel="noopener">Obsidian</a>
        </span>
        <small><a href="https://github.com/TriDiamond/hexo-theme-obsidian/blob/master/CHANGELOG.md" title="v1.4.9.3" target="_blank" rel="noopener">v1.4.9.3</a></small>
        
        </br>
        
        <span class="gradient-text">
            <a href="/" title="" target="_blank" rel="noopener"></a>
        </span>
        
        
        </br>
        
        <span class="gradient-text">
            <a href="/" title="" target="_blank" rel="noopener"></a>
        </span>
        
    </p>
</footer>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX", "TeX"],
      linebreaks: {
        automatic: true
      },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"]
      ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      noUndefined: {
        attributes: {
          mathcolor: "red",
          mathbackground: "#FFEEEE",
          mathsize: "90%"
        }
      },
      Macros: {
        href: "{}"
      }
    },
    messageStyle: "none"
  });
</script>
<script>
  function initialMathJax() {
    MathJax.Hub.Queue(function () {
      var all = MathJax.Hub.getAllJax(),
        i;
      // console.log(all);
      for (i = 0; i < all.length; i += 1) {
        console.log(all[i].SourceElement().parentNode)
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  }

  function reprocessMathJax() {
    if (typeof MathJax !== 'undefined') {
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    }
  }
</script>


 
<link rel="stylesheet" href="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.css">
 
<script src="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.js"></script>
  
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/obsidian.js"></script>
<script src="/js/jquery.truncate.js"></script>
<script src="/js/search.js"></script>
 
<script src="//cdn.bootcss.com/typed.js/2.0.10/typed.min.js"></script>
 
<script src="//cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script>
 
<script src="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>


<script src="https://cdn.bootcss.com/codemirror/5.48.4/codemirror.min.js"></script>
 
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/javascript/javascript.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/css/css.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/xml/xml.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/htmlmixed/htmlmixed.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/clike/clike.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/php/php.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/shell/shell.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/python/python.min.js"></script>
   
<script src="/js/busuanzi.min.js"></script>

<script>
  $(document).ready(function () {
    if ($('span[id^="busuanzi_"]').length) {
      initialBusuanzi();
    }
  });
</script>
 
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css">


<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
  

<script>
  function initialTyped() {
    var typedTextEl = $('.typed-text');
    if (typedTextEl && typedTextEl.length > 0) {
      var typed = new Typed('.typed-text', {
        strings: ['Think like an artist, develop like an artisan', '艺术家思维去思考问题，工匠创造精神去开发'],
        typeSpeed: 90,
        loop: true,
        loopCount: Infinity,
        backSpeed: 20,
      });
    }
  }

  if ($('.article-header') && $('.article-header').length) {
    $(document).ready(function () {
      initialTyped();
    });
  }
</script>




<!-- 引用依赖 -->
<script>document.write(aplayerconf)</script>




</html>
