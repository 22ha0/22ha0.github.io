
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Pytorch学习笔记 - ZZH&#39;s NoteBook</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="TriDiamond Obsidian,"> 
    <meta name="description" content="Anaconda笔记conda 是指调用conda包，create是指创建 -n 是指后面的名字是屋子的名字 pytorch是屋子的名字（可以改成自己想要的名字），python&amp;#x3D;3.6 是,"> 
    <meta name="author" content="ZZH"> 
    <link rel="alternative" href="atom.xml" title="ZZH&#39;s NoteBook" type="application/atom+xml"> 
    <link rel="icon" href="/img/dog.jpg"> 
    
<link rel="stylesheet" href="//at.alicdn.com/t/font_1429596_nzgqgvnmkjb.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.7.2/animate.min.css">

    
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/codemirror.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/theme/dracula.css">

    
<link rel="stylesheet" href="/css/obsidian.css">

    
<link rel="stylesheet" href="/css/ball-atom.min.css">

    
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">

    
    <script>var musiclist = ""</script>
    
<script src="/js/loadaplayer.js"></script>

    <!-- 引用依赖 -->
    
<link rel="stylesheet" href="/aplayer/dist/APlayer.min.css">

    
<script src="/aplayer/dist/APlayer.min.js"></script>
<script src="/js/Meting.min.js"></script>

    
<meta name="generator" content="Hexo 6.3.0"></head>


<body class="loading">
    <div class="loader">
        <div class="la-ball-atom la-2x">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
    <span id="config-title" style="display:none">ZZH&#39;s NoteBook</span>
    <div id="loader"></div>
    <div id="single">
    <div class="scrollbar gradient-bg-rev"></div>
<div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <div class="navigation animated fadeIn fast delay-1s">
        <img id="home-icon" class="icon-home" src="/img/dog.jpg" alt="" data-url="http://example.com">
        <div id="play-icon" title="Play/Pause" class="iconfont icon-play"></div>
        <h3 class="subtitle">Pytorch学习笔记</h3>
        <div class="social">
            <!--        <div class="like-icon">-->
            <!--            <a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
            <!--        </div>-->
            <div>
                <div class="share">
                    
                        <a href="javascript:;" class="iconfont icon-share1"></a>
                        <div class="share-component-cc" data-disabled="facebook,douban,linkedin,diandian,tencent,google"></div>
                    
                </div>
            </div>
        </div>
    </div>
</div>

    <div class="section">
        <div class=article-header-wrapper>
    <div class="article-header">
        <div class="article-cover animated fadeIn" style="
            animation-delay: 600ms;
            animation-duration: 1.2s;
            background-image: 
                radial-gradient(ellipse closest-side, rgba(0, 0, 0, 0.65), #100e17),
                url('https://22ha0.github.io/2023/03/28/Pytorch学习笔记/image-20230720095750550.png') ">
        </div>
        <div class="else">
            <p class="animated fadeInDown">
                
                <a href="/categories/Deep Learn"><b>「
                    </b>DEEP LEARN<b> 」</b></a>
                
                March 28, 2023
            </p>
            <h3 class="post-title animated fadeInDown"><a href="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Pytorch学习笔记" class="">Pytorch学习笔记</a>
            </h3>
            
            <p class="post-count animated fadeInDown">
                
                <span>
                    <b class="iconfont icon-text2"></b> <i>Words count</i>
                    49k
                </span>
                
                
                <span>
                    <b class="iconfont icon-timer__s"></b> <i>Reading time</i>
                    44 mins.
                </span>
                
                
                
                <span id="busuanzi_container_page_pv">
                    <b class="iconfont icon-read"></b> <i>Read count</i>
                    <span id="busuanzi_value_page_pv">0</span>
                </span>
                
            </p>
            
            
            <ul class="animated fadeInDown post-tags-list" itemprop="keywords"><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Deep-Learn/" rel="tag">Deep Learn</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>
            
        </div>
    </div>
</div>

<div class="screen-gradient-after">
    <div class="screen-gradient-content">
        <div class="screen-gradient-content-inside">
            <div class="bold-underline-links screen-gradient-sponsor">
                <p>
                    <span class="animated fadeIn delay-1s"></span>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="article">
    <div class='main'>
        <div class="content markdown animated fadeIn">
            <h1 id="Anaconda笔记"><a href="#Anaconda笔记" class="headerlink" title="Anaconda笔记"></a>Anaconda笔记</h1><p>conda 是指调用conda包，create是指创建 -n 是指后面的名字是屋子的名字 pytorch是屋子的名字（可以改成自己想要的名字），python&#x3D;3.6 是指创建的屋子是python3.6版本的屋子</p>
<pre><code class="bash">conda create -n pytorch python=3.6
</code></pre>
<p>激活环境</p>
<pre><code class="bash">conda activate 环境名称
</code></pre>
<p>注销环境</p>
<pre><code class="bash">conda deactivate 
</code></pre>
<p>在anaconda中安装pytorch：直接去官网选择对应版本复制指令</p>
<p>anaconda中安装模块(jupyter)</p>
<pre><code class="bash">conda install nb_conda
</code></pre>
<p>启动jupyter notebook</p>
<pre><code class="bash">jupyter notebook
</code></pre>
<p>查看conda所有环境</p>
<pre><code class="python">conda info --envs
</code></pre>
<p>创建虚拟环境：conda create -n virtual_name python&#x3D;3.x</p>
<p>显示虚拟环境：conda env list</p>
<p>切换虚拟环境：activate virtual_name</p>
<p>退出虚拟环境：conda deactivate</p>
<p>删除虚拟环境：conda remove -n virtual_name –all</p>
<h1 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h1><pre><code class="python">torch.cuda.is_available() #cuda是否可用
</code></pre>
<p>python中两个重要法宝函数 <code>dir()</code> <code>help()</code></p>
<h2 id="Pytorch-加载数据"><a href="#Pytorch-加载数据" class="headerlink" title="Pytorch 加载数据"></a>Pytorch 加载数据</h2><h3 id="dataset-：提供一种方式去获取数据及label"><a href="#dataset-：提供一种方式去获取数据及label" class="headerlink" title="dataset ：提供一种方式去获取数据及label"></a>dataset ：提供一种方式去获取数据及label</h3><p>功能1：如何获取每一个数据及其label</p>
<p>功能2：告诉我们有多少个数据 </p>
<pre><code class="python">from torch.utils.data import Dataset
</code></pre>
<pre><code class="python">import os
path_list = os.listdir(dir_path) 
#把路径dir_path下的所有文件名地址存成一个list

path=os.path.join(root_dir,label_dir)
#拼接路径
</code></pre>
<p>Dataset实战</p>
<pre><code class="python">from torch.utils.data import Dataset
from PIL import Image
import os

class MyData(Dataset):

    def __init__(self, root_dir, label_dir):
        self.root_dir = root_dir
        self.label_dir = label_dir
        self.path = os.path.join(self.root_dir, self.label_dir)
        self.img_path = os.listdir(self.path)
        pass

    def __getitem__(self, index):#获取其中一个图片
        img_name = self.img_path[index]
        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)
        img = Image.open(img_item_path)
        label = self.label_dir
        return img,label
    
    def __len__(self):
        return len(self.img_path)
root_dir = &#39;E:\Desktop\StudyPytorch\Dataset\hymenoptera_data/train&#39;
label_dir = &#39;ants&#39;
#创建实例
ants_dataset = MyData(root_dir,label_dir)
</code></pre>
<h3 id="DataLoader的使用"><a href="#DataLoader的使用" class="headerlink" title="DataLoader的使用"></a>DataLoader的使用</h3><pre><code class="python">DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,
           batch_sampler=None, num_workers=0, collate_fn=None,
           pin_memory=False, drop_last=False, timeout=0,
           worker_init_fn=None, *, prefetch_factor=2,
           persistent_workers=False)
</code></pre>
<ul>
<li><strong>dataset</strong> (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.8.1/data.html?highlight=dataloader#torch.utils.data.Dataset">Dataset</a>) – dataset from which to load the data.</li>
<li><strong>batch_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>,</em> <em>optional</em>) – how many samples per batch to load (default: 1).</li>
<li><strong>shuffle</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a><em>,</em> <em>optional</em>) – set to True to have the data reshuffled at every epoch (default: False).</li>
<li><strong>sampler</strong> (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.8.1/data.html?highlight=dataloader#torch.utils.data.Sampler">Sampler</a> <em>or</em> <em>Iterable</em><em>,</em> <em>optional</em>) – defines the strategy to draw samples from the dataset. Can be any Iterable with <strong>len</strong> implemented. If specified, shuffle must not be specified.</li>
<li><strong>batch_sampler</strong> (<a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.8.1/data.html?highlight=dataloader#torch.utils.data.Sampler">Sampler</a> <em>or</em> <em>Iterable</em><em>,</em> <em>optional</em>) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.</li>
<li><strong>num_workers</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>,</em> <em>optional</em>) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)</li>
<li><strong>collate_fn</strong> (<em>callable</em><em>,</em> <em>optional</em>) – merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.</li>
<li><strong>pin_memory</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a><em>,</em> <em>optional</em>) – If True, the data loader will copy Tensors into CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below.</li>
<li><strong>drop_last</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a><em>, optional</em>) – set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)（除不尽是否舍去）</li>
<li><strong>timeout</strong> (<em>numeric</em><em>,</em> <em>optional</em>) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0)</li>
<li><strong>worker_init_fn</strong> (<em>callable</em><em>,</em> <em>optional</em>) – If not None, this will be called on each worker subprocess with the worker id (an int in [0,num_workers-1]) as input, after seeding and before data loading. (default: None)</li>
<li><strong>prefetch_factor</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>,</em> <em>optional</em><em>,</em> <em>keyword-only arg</em>) – Number of samples loaded in advance by each worker. 2 means there will be a total of 2 * num_workers samples prefetched across all workers. (default: 2)</li>
<li><strong>persistent_workers</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a><em>, optional</em>) – If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset instances alive. (default: False)</li>
</ul>
<h2 id="TensorBorad的使用"><a href="#TensorBorad的使用" class="headerlink" title="TensorBorad的使用"></a>TensorBorad的使用</h2><h3 id="add-scalar"><a href="#add-scalar" class="headerlink" title="add_scalar()"></a>add_scalar()</h3><p>global_step 对应x轴</p>
<p>scalar_value 对应y轴</p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672234090005-5ed84d38-ba23-4e18-90bc-58cde1588890.png" class title="img">

<pre><code class="python">from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter(&quot;logs&quot;) #写入事件的文件夹
# writer.add_image()
for i in range(100):
    writer.add_scalar(tag=&quot;y=x&quot;,global_step=i,scalar_value=i)
writer.close()
</code></pre>
<p>打开TensorBoard方法</p>
<ol>
<li>打开ＣＭＤ输入（要先找到事件所在路径）</li>
</ol>
<pre><code class="python">tensorboard --logdir=logs -port=6007
</code></pre>
<p>–logdir 指定目录 –port 指定端口</p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672234705128-0d918e9b-79d5-4312-a130-86488087dd6d.png" class title="img">



<h3 id="add-image"><a href="#add-image" class="headerlink" title="add_image()"></a>add_image()</h3><p>把PIL读出来的图片文件转换成np的array（也可以用opencv读入，opencv读入就是np数组类型的数据）</p>
<pre><code class="python">image_path = &#39;&#39;
from PIL import Image
img = Image.open(image_path)
print(type(img))#查看原本的类型
import numpy as np
img_array = np.array(img) 
</code></pre>
<p>add_image()的使用</p>
<pre><code class="python">from torch.utils.tensorboard import SummaryWriter
from PIL import Image
import numpy as np
writer = SummaryWriter(&quot;logs&quot;) #写入事件的文件夹
img_path = &#39;E:\Desktop\StudyPytorch\Dataset\hymenoptera_data/train/ants/0013035.jpg&#39;
img_PIL = Image.open(img_path)
img_array = np.array(img_PIL)
#将img转换成np数组
#如果图片格式不是为(3,H,W),需要调整
#如例子的图片格式为(H,W,3)就需要调整
#global_step训练步数
writer.add_image(tag=&#39;test&#39;,img_tensor=img_array, global_step=1,dataformats=&quot;HWC&quot;)
writer.close()
</code></pre>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672236770272-9a5966f7-6cfb-4739-93dd-b215ffbaaa55.png" class title="img">

<h3 id="Transforms的使用（torchvision中的transforms）"><a href="#Transforms的使用（torchvision中的transforms）" class="headerlink" title="Transforms的使用（torchvision中的transforms）"></a>Transforms的使用（torchvision中的transforms）</h3><p>对图片进行一些变换</p>
<h4 id="transforms结构及用法"><a href="#transforms结构及用法" class="headerlink" title="transforms结构及用法"></a>transforms结构及用法</h4> <img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672285838070-c7d47f0e-a82f-4f0a-b44c-181418d18d86.png" class title="img">

<pre><code class="python">from torchvision import transforms
from PIL import Image
img_path=&#39;E:\Desktop\StudyPytorch\Dataset\hymenoptera_data/train/ants/0013035.jpg&#39;
img = Image.open(img_path)
tensor_trans = transforms.ToTensor() #新建ToTensor对象 
tensor_img = tensor_trans(img) #将img转化成tensor_img 包装了训练神经网络所需要的一些类型
print(tensor_img)
tensor格式也可以直接传入TensorBoard中
</code></pre>
<h3 id="常见的Transforms"><a href="#常见的Transforms" class="headerlink" title="常见的Transforms"></a>常见的Transforms</h3><p>Python中__call__的用法</p>
<pre><code class="python">class Person:
    def __call__(self,name):
        print(&quot;__call__&quot;+&quot;hello&quot;+name)
        pass
    def hello(self, name):
        print(&quot;hello&quot;+name)
        pass

person = Person()
person(&quot;zhangshan&quot;)
# __call__hellozhangshan
person.hello(&quot;lisi&quot;)
# hellolisi
</code></pre>
<h4 id="ToTensor的使用"><a href="#ToTensor的使用" class="headerlink" title="ToTensor的使用"></a>ToTensor的使用</h4><pre><code class="python">from PIL import Image
from torchvision import transforms
img = Image.open(&#39;E:\Desktop\StudyPytorch\Dataset\hymenoptera_data/train/ants/0013035.jpg&#39;)
trans_totensor = transforms.ToTensor()
img_tensor = trans_totensor(img)
</code></pre>
<h4 id="Normalize-归一化"><a href="#Normalize-归一化" class="headerlink" title="Normalize()归一化"></a>Normalize()归一化</h4><pre><code class="python">trans_norm = transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])
img_norm = trans_norm(img_tensor)
</code></pre>
<h4 id="Resize-重新调整尺寸"><a href="#Resize-重新调整尺寸" class="headerlink" title="Resize()重新调整尺寸"></a>Resize()重新调整尺寸</h4><pre><code class="python">trans_resize = transforms.Resize((W,H))
img_resize = trans_resize(img)
</code></pre>
<h4 id="Compose-合并多个操作"><a href="#Compose-合并多个操作" class="headerlink" title="Compose()合并多个操作"></a>Compose()合并多个操作</h4><pre><code class="python">trans_compose = transforms.Compose([trans_resize,trans_totensor]) #进行两步变换
</code></pre>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672307716682-45cfcb01-48b3-497c-b4fd-383bab66a6e5.png" class title="img">

<h4 id="RandomCrop-随机裁剪"><a href="#RandomCrop-随机裁剪" class="headerlink" title="RandomCrop()随机裁剪"></a>RandomCrop()随机裁剪</h4><pre><code class="python">trans_random = transforms.RandomCrop((500,1000))#(W,H)
</code></pre>
<h3 id="torchvision中数据集的使用"><a href="#torchvision中数据集的使用" class="headerlink" title="torchvision中数据集的使用"></a>torchvision中数据集的使用</h3><p><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/index.html">https://pytorch.org/vision/stable/index.html</a></p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672309504083-6c1426e3-0f62-4750-871f-26f956654567.png" class title="img">

<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672321335516-24f74238-7fc9-46ad-a00a-87ecdba7dde3.png" class title="img">

<h2 id="神经网络的基本骨架-nn-Module的使用"><a href="#神经网络的基本骨架-nn-Module的使用" class="headerlink" title="神经网络的基本骨架 nn.Module的使用"></a>神经网络的基本骨架 nn.Module的使用</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/nn.html">https://pytorch.org/docs/1.13/nn.html</a></p>
<pre><code class="python">import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>relu 非线性 conv 卷积</p>
<h2 id="卷积层convolution"><a href="#卷积层convolution" class="headerlink" title="卷积层convolution"></a>卷积层convolution</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">https://pytorch.org/docs/1.13/generated/torch.nn.Conv2d.html#torch.nn.Conv2d</a></p>
<ul>
<li><strong>in_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a>) – Number of channels in the input image输入图像的通道数 </li>
<li><strong>out_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a>) – Number of channels produced by the convolution 输出图像的通道数</li>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>) – Size of the convolving kernel 卷积核的尺寸</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a><em>, optional</em>) – Stride of the convolution. Default: 1 步进大小</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str">str</a><em>, optional</em>) – Padding added to all four sides of the input. Default: 0 卷积过程中是否填充周围</li>
<li><strong>padding_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str">str</a><em>,</em> <em>optional</em>) – ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’</li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a><em>, optional</em>) – Spacing between kernel elements. Default: 1卷积核增加的距离</li>
<li><strong>groups</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</li>
<li><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a><em>, optional</em>) – If True, adds a learnable bias to the output. Default: True 是否加偏置</li>
</ul>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672455800648-a6fd1d70-e902-4257-aaee-ae06a878f349.png" class title="img"> <img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672471041306-9276b146-2fe1-47bd-bc81-911fce82b34d.png" class title="img">

<pre><code class="python">from torch.utils.tensorboard import SummaryWriter
import torch
import torchvision
from torch import nn
from torch.utils.data import DataLoader
from torch.nn import Conv2d

dataset = torchvision.datasets.CIFAR10(&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)

dataloader = DataLoader(dataset,batch_size=64)

class CNN(nn.Module):
    def __init__(self) -&gt; None:
        super(CNN,self).__init__()
        self.conv1 = Conv2d(in_channels=3,out_channels=6,kernel_size=3,stride=1,padding=0)
    
    def forward(self,x):
        x = self.conv1(x)
        return x
cnn = CNN()
writer = SummaryWriter(&#39;../logscnn&#39;)
step = 0
for data in dataloader:
    imgs,targets = data
    output = cnn(imgs)
    print(imgs.shape)
    print(output.shape)
    writer.add_images(&#39;input&#39;,imgs,step)
    #Size([64, 6, 30, 30])-&gt;Size([xxx, 3, 30, 30])
    output = torch.reshape(output,(-1,3,30,30))
    writer.add_images(&#39;output&#39;,output,step)
    step = step + 1
</code></pre>
<p>卷积结果</p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672458742123-97b23649-f381-4f9a-b2ad-05c1d1300ec9.png" class title="img">

<h2 id="最大池化"><a href="#最大池化" class="headerlink" title="最大池化"></a>最大池化</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d">https://pytorch.org/docs/1.13/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d</a></p>
<pre><code class="python">class
torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
</code></pre>
<ul>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>]]</em>) – the size of the window to take a max over 池化窗口大小</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>]**]</em>) – the stride of the window. Default value is kernel_size</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>]**]</em>) – implicit zero padding to be added on both sides</li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a><em>[*<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a></em>,* <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int">int</a><em>]**]</em>) – a parameter that controls the stride of elements in the window</li>
<li><strong>return_indices</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a>) – if True, will return the max indices along with the outputs. Useful for <a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d">torch.nn.MaxUnpool2d</a> later</li>
<li><strong>ceil_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a>) – when True, will use ceil instead of floor to compute the output shape</li>
</ul>
<h2 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/nn.html#non-linear-activations-weighted-sum-nonlinearity">https://pytorch.org/docs/1.13/nn.html#non-linear-activations-weighted-sum-nonlinearity</a></p>
<h2 id="线性层"><a href="#线性层" class="headerlink" title="线性层"></a>线性层</h2> <img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672478924304-68acb2ce-a56c-4d91-94a0-0f68506edea6.png" class title="img">

<pre><code class="python">class
torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)
</code></pre>
<h2 id="sequential-序列"><a href="#sequential-序列" class="headerlink" title="sequential 序列"></a>sequential 序列</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/generated/torch.nn.Sequential.html#torch.nn.Sequential">https://pytorch.org/docs/1.13/generated/torch.nn.Sequential.html#torch.nn.Sequential</a></p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672490571390-27b8bdf9-ffcf-4eed-8874-64cf4a139485.png" class title="img">

<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/nn.html#loss-functions">https://pytorch.org/docs/1.13/nn.html#loss-functions</a></p>
<pre><code class="python">torch.nn.L1Loss(size_average=None, reduce=None, reduction=&#39;mean&#39;)
</code></pre>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><pre><code class="python">output.backward()
</code></pre>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/optim.html">https://pytorch.org/docs/1.13/optim.html</a></p>
<pre><code class="python">optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
optimizer = optim.Adam([var1, var2], lr=0.0001)
for input, target in dataset:
    optimizer.zero_grad()
    output = model(input)
    loss = loss_fn(output, target)
    loss.backward()
    optimizer.step()
</code></pre>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672645967466-7bc6841e-863e-481a-8206-589d9485d36b.png" class title="img">

<h2 id="现有网络模型的使用和修改"><a href="#现有网络模型的使用和修改" class="headerlink" title="现有网络模型的使用和修改"></a>现有网络模型的使用和修改</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html">https://pytorch.org/vision/stable/models.html</a></p>
<p>添加一层</p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672649572712-4d8620d9-7094-4f21-a14c-9989c848005d.png" class title="img">

<p> 在classifier中加  </p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672649697407-d4b4d39f-a798-4f0a-af74-7abf6fc45fb7.png" class title="img">

<h2 id="网络模型的保持与读取"><a href="#网络模型的保持与读取" class="headerlink" title="网络模型的保持与读取"></a>网络模型的保持与读取</h2><p> 保存方式1(保存模型+参数)</p>
<pre><code class="python">torch.save(vgg16,&quot;name.pth&quot;)
</code></pre>
<p>加载模型方式1-&gt;保存方式1</p>
<pre><code class="python">model = torch.load(&#39;name.pth&#39;)
</code></pre>
<p>保存方法2（保存参数）官方推荐</p>
<pre><code class="python">torch.save(vgg16.state_dict(),&quot;name.pth&quot;)#把vgg16的状态转换成字典格式保存
</code></pre>
<p>加载模型方式2-&gt;保存方式2</p>
<pre><code class="python">vgg16 = torchvision.model.vgg16(pretrained=False)#先创建模型
vgg16.load_state_dict(torch.load(&quot;name.pth&quot;))#再载入字典数据
</code></pre>
<h2 id="完整模型训练套路（一）"><a href="#完整模型训练套路（一）" class="headerlink" title="完整模型训练套路（一）"></a>完整模型训练套路（一）</h2><p>以CIFAR10为例子</p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672888327081-71e0a548-a0a2-49e1-a423-cecb2e850cab.png" class title="img">

<p>搭建模型并进行测试</p>
<pre><code class="python">import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn

#准备数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=True,transform=torchvision.transforms.ToTensor(),download=True)
test_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)
#数据集的长度
train_size = len(train_data)
test_size = len(test_data)
print(&quot;训练集的长度为：&#123;&#125;&quot;.format(train_size))
print(&quot;测试集的长度为：&#123;&#125;&quot;.format(test_size))

#利用DataLoader来加载数据
train_dataloader = DataLoader(train_data,batch_size=64)
test_dataloader= DataLoader(test_data,batch_size=64)

#搭建神经网络
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x

if __name__==&#39;__main__&#39;:
    model = CIFAR10Model()
    input = torch.ones((64,3,32,32))#创建一个64张图片的测试样例测试网络是否正确
    output = model(input)
    print(output.shape)
import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn

#准备数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=True,transform=torchvision.transforms.ToTensor(),download=True)
test_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)
#数据集的长度
train_size = len(train_data)
test_size = len(test_data)
print(&quot;训练集的长度为：&#123;&#125;&quot;.format(train_size))
print(&quot;测试集的长度为：&#123;&#125;&quot;.format(test_size))

#利用DataLoader来加载数据
train_dataloader = DataLoader(train_data,batch_size=64)
test_dataloader= DataLoader(test_data,batch_size=64)

#搭建神经网络
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x

if __name__==&#39;__main__&#39;:
    model = CIFAR10Model()
    #损失函数
    loss_f = nn.CrossEntropyLoss()
    #优化器
    #learning_rate = 0.01
    #1e-2 = 1x10^-2
    learning_rate = 1e-2
    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)

    #设置训练网络的一些参数
    #记录训练的次数
    total_train_step = 0
    #记录测试的次数
    total_test_step = 0
    #训练的轮数
    epoch = 10

    for i in range(epoch):
        print(&#39;第&#123;&#125;轮训练开始&#39;.format(i+1))
           # 训练开始
        for data in train_dataloader:
            imgs,targets = data
            outputs = model(imgs)
            loss = loss_f(outputs,targets)

            #用优化器梯度清零
            optimizer.zero_grad()
            #反向传播
            loss.backward()
            #参数优化
            optimizer.step()
        total_train_step = total_train_step + 1
        print(&quot;训练次数：&#123;&#125;，loss:&#123;&#125;&quot;.format(total_train_step,loss.item()))
</code></pre>
<h2 id="完整训练套路（二）"><a href="#完整训练套路（二）" class="headerlink" title="完整训练套路（二）"></a>完整训练套路（二）</h2><p>使用验证集测试，并将loss添加导TensorBoard中</p>
<pre><code class="python">import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter

#准备数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=True,transform=torchvision.transforms.ToTensor(),download=True)
test_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)
#数据集的长度
train_size = len(train_data)
test_size = len(test_data)
print(&quot;训练集的长度为：&#123;&#125;&quot;.format(train_size))
print(&quot;测试集的长度为：&#123;&#125;&quot;.format(test_size))

#利用DataLoader来加载数据
train_dataloader = DataLoader(train_data,batch_size=64)
test_dataloader= DataLoader(test_data,batch_size=64)

#搭建神经网络
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x

if __name__==&#39;__main__&#39;:
    model = CIFAR10Model()
    #损失函数
    loss_f = nn.CrossEntropyLoss()
    #优化器
    #learning_rate = 0.01
    #1e-2 = 1x10^-2
    learning_rate = 1e-2
    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)

    #设置训练网络的一些参数
    #记录训练的次数
    total_train_step = 0
    #记录测试的次数
    total_test_step = 0
    #训练的轮数
    epoch = 10
    
    #添加tensorboard
    writer = SummaryWriter(&quot;../logs_train1&quot;)
    for i in range(epoch):
        print(&#39;&gt;&gt;&gt;&gt;&gt;&gt;第&#123;&#125;轮训练开始&#39;.format(i+1))
    # 训练开始
        for data in train_dataloader:
            imgs,targets = data
            outputs = model(imgs)
            loss = loss_f(outputs,targets)

            #用优化器梯度清零
            optimizer.zero_grad()
            #反向传播
            loss.backward()
            #参数优化
            optimizer.step()
            total_train_step = total_train_step + 1
            print(&quot;训练次数：&#123;&#125;，loss:&#123;&#125;&quot;.format(total_train_step,loss.item()))

            #添加tensorboard
            writer.add_scalar(&#39;train_loss&#39;,loss.item(),total_test_step)

        #验证阶段（测试）  
        #在with中的代码就没有梯度，保证不会对模型进行调优
        total_test_loss = 0
        total_test_step = total_test_step + 1
        with torch.no_grad():
            for data in test_dataloader:
                imgs,targets = data
                outputs = model(imgs)
                loss = loss_f(outputs,targets)
                total_test_loss = total_test_loss+loss.item()
        print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))
        writer.add_scalar(&quot;test_loss&quot;,total_test_loss,total_test_step)
    writer.close()
</code></pre>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672991421495-8dc807eb-7a48-4c19-b1df-7f97c768fa3d.png" class title="img">



<p>训练完并保存模型</p>
<pre><code class="python">import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter

#准备数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=True,transform=torchvision.transforms.ToTensor(),download=True)
test_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)
#数据集的长度
train_size = len(train_data)
test_size = len(test_data)
print(&quot;训练集的长度为：&#123;&#125;&quot;.format(train_size))
print(&quot;测试集的长度为：&#123;&#125;&quot;.format(test_size))

#利用DataLoader来加载数据
train_dataloader = DataLoader(train_data,batch_size=64)
test_dataloader= DataLoader(test_data,batch_size=64)

#搭建神经网络
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x

if __name__==&#39;__main__&#39;:
    model = CIFAR10Model()
    #损失函数
    loss_f = nn.CrossEntropyLoss()
    #优化器
    #learning_rate = 0.01
    #1e-2 = 1x10^-2
    learning_rate = 1e-2
    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)

    #设置训练网络的一些参数
    #记录训练的次数
    total_train_step = 0
    #记录测试的次数
    total_test_step = 0
    #训练的轮数
    epoch = 10
    
    #添加tensorboard
    writer = SummaryWriter(&quot;../logs_train1&quot;)
    for i in range(epoch):
        print(&#39;&gt;&gt;&gt;&gt;&gt;&gt;第&#123;&#125;轮训练开始&#39;.format(i+1))
    # 训练开始
        for data in train_dataloader:
            imgs,targets = data
            outputs = model(imgs)
            loss = loss_f(outputs,targets)

            #用优化器梯度清零
            optimizer.zero_grad()
            #反向传播
            loss.backward()
            #参数优化
            optimizer.step()
            total_train_step = total_train_step + 1
            print(&quot;训练次数：&#123;&#125;，loss:&#123;&#125;&quot;.format(total_train_step,loss.item()))

            #添加tensorboard
            writer.add_scalar(&#39;train_loss&#39;,loss.item(),total_test_step)

        #验证阶段（测试）  
        #在with中的代码就没有梯度，保证不会对模型进行调优
        total_test_loss = 0
        total_test_step = total_test_step + 1
        with torch.no_grad():
            for data in test_dataloader:
                imgs,targets = data
                outputs = model(imgs)
                loss = loss_f(outputs,targets)
                total_test_loss = total_test_loss+loss.item()
        print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))
        writer.add_scalar(&quot;test_loss&quot;,total_test_loss,total_test_step)

        #保存每一轮的模型
        torch.save(model,&quot;model_&#123;&#125;.pth&quot;.format(epoch))
        print(&quot;模型已保存&quot;)
    writer.close()
</code></pre>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1672993369898-df55722b-9c0e-4c92-8520-60c337694773.png" class title="img">





<p>argmax</p>
<pre><code class="python">import torch
outputs = torch.tensor([[0.1,0.2],[0.3,0.4]])
#输出最大概率的类别下标
preds=outputs.argmax(1)#1为横向 0为纵向
targets = torch.tensor([0,1])
print((preds == targets).sum())#计算出正确的个数
</code></pre>
<p>计算出整体的正确率</p>
<pre><code class="python">import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter


#准备数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=True,transform=torchvision.transforms.ToTensor(),download=True)
test_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)
#数据集的长度
train_size = len(train_data)
test_size = len(test_data)
print(&quot;训练集的长度为：&#123;&#125;&quot;.format(train_size))
print(&quot;测试集的长度为：&#123;&#125;&quot;.format(test_size))


#利用DataLoader来加载数据
train_dataloader = DataLoader(train_data,batch_size=64)
test_dataloader= DataLoader(test_data,batch_size=64)


#搭建神经网络
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x


if __name__==&#39;__main__&#39;:
    model = CIFAR10Model()
    #损失函数
    loss_f = nn.CrossEntropyLoss()
    #优化器
    #learning_rate = 0.01
    #1e-2 = 1x10^-2
    learning_rate = 1e-2
    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)


    #设置训练网络的一些参数
    #记录训练的次数
    total_train_step = 0
    #记录测试的次数
    total_test_step = 0
    #训练的轮数
    epoch = 10
    
    #添加tensorboard
    writer = SummaryWriter(&quot;../logs_train1&quot;)
    for i in range(epoch):
        print(&#39;&gt;&gt;&gt;&gt;&gt;&gt;第&#123;&#125;轮训练开始&#39;.format(i+1))
    # 训练开始
        for data in train_dataloader:
            imgs,targets = data
            outputs = model(imgs)
            loss = loss_f(outputs,targets)


            #用优化器梯度清零
            optimizer.zero_grad()
            #反向传播
            loss.backward()
            #参数优化
            optimizer.step()
            total_train_step = total_train_step + 1
            print(&quot;训练次数：&#123;&#125;，loss:&#123;&#125;&quot;.format(total_train_step,loss.item()))


            #添加tensorboard
            writer.add_scalar(&#39;train_loss&#39;,loss.item(),total_test_step)


        #验证阶段（测试）  
        #在with中的代码就没有梯度，保证不会对模型进行调优
        total_test_loss = 0
        total_accuracy = 0
        total_test_step = total_test_step + 1
        with torch.no_grad():
            for data in test_dataloader:
                imgs,targets = data
                outputs = model(imgs)
                loss = loss_f(outputs,targets)
                total_test_loss = total_test_loss+loss.item()
                accuracy = (outputs.argmax(1) == targets).sum() #单轮正确的个数
                total_accuracy = total_accuracy+accuracy #总的正确的个数
        print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))
        print(&quot;整体测试集上的正确率：&#123;&#125;&quot;.format(total_accuracy/test_size))
        writer.add_scalar(&quot;test_loss&quot;,total_test_loss,total_test_step)
        writer.add_scalar(&quot;test_accuracy&quot;,total_accuracy/test_size,total_test_step)



        #保存每一轮的模型
        torch.save(model,&quot;model_&#123;&#125;.pth&quot;.format(i))
        print(&quot;模型已保存&quot;)
    writer.close()
</code></pre>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1673059964590-ac5ddbee-2531-43f5-a889-1c05c4c62f0c.png" class title="img">

<h2 id="完整的模型训练套路3"><a href="#完整的模型训练套路3" class="headerlink" title="完整的模型训练套路3"></a>完整的模型训练套路3</h2><p>把网络设置成训练模式或者测试模式67行和90行</p>
<pre><code class="python">import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter


#准备数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=True,transform=torchvision.transforms.ToTensor(),download=True)
test_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)
#数据集的长度
train_size = len(train_data)
test_size = len(test_data)
print(&quot;训练集的长度为：&#123;&#125;&quot;.format(train_size))
print(&quot;测试集的长度为：&#123;&#125;&quot;.format(test_size))


#利用DataLoader来加载数据
train_dataloader = DataLoader(train_data,batch_size=64)
test_dataloader= DataLoader(test_data,batch_size=64)


#搭建神经网络
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x


if __name__==&#39;__main__&#39;:
    model = CIFAR10Model()
    #损失函数
    loss_f = nn.CrossEntropyLoss()
    #优化器
    #learning_rate = 0.01
    #1e-2 = 1x10^-2
    learning_rate = 1e-2
    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)


    #设置训练网络的一些参数
    #记录训练的次数
    total_train_step = 0
    #记录测试的次数
    total_test_step = 0
    #训练的轮数
    epoch = 10
    
    #添加tensorboard
    writer = SummaryWriter(&quot;../logs_train1&quot;)
    for i in range(epoch):
        print(&#39;&gt;&gt;&gt;&gt;&gt;&gt;第&#123;&#125;轮训练开始&#39;.format(i+1))
    # 训练开始
        model.train()#将网络设置成训练模式（只对部分网络起作用）
        for data in train_dataloader:
            imgs,targets = data
            outputs = model(imgs)
            loss = loss_f(outputs,targets)


            #用优化器梯度清零
            optimizer.zero_grad()
            #反向传播
            loss.backward()
            #参数优化
            optimizer.step()
            total_train_step = total_train_step + 1
            print(&quot;训练次数：&#123;&#125;，loss:&#123;&#125;&quot;.format(total_train_step,loss.item()))


            #添加tensorboard
            writer.add_scalar(&#39;train_loss&#39;,loss.item(),total_test_step)


        #验证阶段（测试）  
        #在with中的代码就没有梯度，保证不会对模型进行调优
        model.eval()#将网络设置成测试模式（只对部分网络起作用）
        total_test_loss = 0
        total_accuracy = 0
        total_test_step = total_test_step + 1
        with torch.no_grad():
            for data in test_dataloader:
                imgs,targets = data
                outputs = model(imgs)
                loss = loss_f(outputs,targets)
                total_test_loss = total_test_loss+loss.item()
                accuracy = (outputs.argmax(1) == targets).sum() #单轮正确的个数
                total_accuracy = total_accuracy+accuracy #总的正确的个数
        print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))
        print(&quot;整体测试集上的正确率：&#123;&#125;&quot;.format(total_accuracy/test_size))
        writer.add_scalar(&quot;test_loss&quot;,total_test_loss,total_test_step)
        writer.add_scalar(&quot;test_accuracy&quot;,total_accuracy/test_size,total_test_step)



        #保存每一轮的模型
        torch.save(model,&quot;model_&#123;&#125;.pth&quot;.format(i))
        print(&quot;模型已保存&quot;)
    writer.close()
</code></pre>
<p>以下模式只对特定的层有效</p>
<p>train模式</p>
<p>train(<em>mode&#x3D;True</em>)[<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.train">source]</a></p>
<p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training&#x2F;evaluation mode, if they are affected, e.g. <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout">Dropout</a>, BatchNorm, etc.</p>
<p>Parameters:</p>
<p><strong>mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool">bool</a>) – whether to set training mode (True) or evaluation mode (False). Default: True.</p>
<p>Returns:</p>
<p>self</p>
<p>Return type:</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></p>
<p>eval模式</p>
<p>eval()[<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval">source]</a></p>
<p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training&#x2F;evaluation mode, if they are affected, e.g. <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout">Dropout</a>, BatchNorm, etc.</p>
<p>This is equivalent with <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train">self.train(False)</a>.</p>
<p>See <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc">Locally disabling gradient computation</a> for a comparison between .eval() and several similar mechanisms that may be confused with it.</p>
<p>Returns:</p>
<p>self</p>
<p>Return type:</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></p>
<h2 id="使用GPU训练（一）"><a href="#使用GPU训练（一）" class="headerlink" title="使用GPU训练（一）"></a>使用GPU训练（一）</h2><p>用GPU训练的模型 要用GPU加载</p>
<p>找到网络模型，数据（输入、标注）、损失函数加上.cude()</p>
<pre><code class="python">import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter

#准备数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=True,transform=torchvision.transforms.ToTensor(),download=True)
test_data = torchvision.datasets.CIFAR10(root=&quot;../data&quot;,train=False,transform=torchvision.transforms.ToTensor(),download=True)
#数据集的长度
train_size = len(train_data)
test_size = len(test_data)
print(&quot;训练集的长度为：&#123;&#125;&quot;.format(train_size))
print(&quot;测试集的长度为：&#123;&#125;&quot;.format(test_size))

#利用DataLoader来加载数据
train_dataloader = DataLoader(train_data,batch_size=64)
test_dataloader= DataLoader(test_data,batch_size=64)

#搭建神经网络
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x

if __name__==&#39;__main__&#39;:
    model = CIFAR10Model()

    #-----------------------------
    model = model.cuda()
    #-----------------------------

    #损失函数
    loss_f = nn.CrossEntropyLoss()

    #-----------------------------
    loss_f = loss_f.cuda()
    #-----------------------------

    #优化器
    #learning_rate = 0.01
    #1e-2 = 1x10^-2
    learning_rate = 1e-2
    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)

    #设置训练网络的一些参数
    #记录训练的次数
    total_train_step = 0
    #记录测试的次数
    total_test_step = 0
    #训练的轮数
    epoch = 10
    
    #添加tensorboard
    writer = SummaryWriter(&quot;../logs_train1&quot;)
    for i in range(epoch):
        print(&#39;&gt;&gt;&gt;&gt;&gt;&gt;第&#123;&#125;轮训练开始&#39;.format(i+1))
    # 训练开始
        model.train()#将网络设置成训练模式（只对部分网络起作用）
        for data in train_dataloader:
            imgs,targets = data

            #-----------------------------
            imgs = imgs.cuda()
            targets = targets.cuda()
            #-----------------------------

            outputs = model(imgs)
            loss = loss_f(outputs,targets)

            #用优化器梯度清零
            optimizer.zero_grad()
            #反向传播
            loss.backward()
            #参数优化
            optimizer.step()
            total_train_step = total_train_step + 1
            print(&quot;训练次数：&#123;&#125;，loss:&#123;&#125;&quot;.format(total_train_step,loss.item()))

            #添加tensorboard
            writer.add_scalar(&#39;train_loss&#39;,loss.item(),total_test_step)

        #验证阶段（测试）  
        #在with中的代码就没有梯度，保证不会对模型进行调优
        model.eval()#将网络设置成测试模式（只对部分网络起作用）
        total_test_loss = 0
        total_accuracy = 0
        total_test_step = total_test_step + 1
        with torch.no_grad():
            for data in test_dataloader:
                imgs,targets = data

                #-----------------------------
                imgs = imgs.cuda()
                targets = targets.cuda()
                #-----------------------------
                
                outputs = model(imgs)
                loss = loss_f(outputs,targets)
                total_test_loss = total_test_loss+loss.item()
                accuracy = (outputs.argmax(1) == targets).sum() #单轮正确的个数
                total_accuracy = total_accuracy+accuracy #总的正确的个数
        print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))
        print(&quot;整体测试集上的正确率：&#123;&#125;&quot;.format(total_accuracy/test_size))
        writer.add_scalar(&quot;test_loss&quot;,total_test_loss,total_test_step)
        writer.add_scalar(&quot;test_accuracy&quot;,total_accuracy/test_size,total_test_step)


        #保存每一轮的模型
        torch.save(model,&quot;model_&#123;&#125;.pth&quot;.format(i))
        print(&quot;模型已保存&quot;)
    writer.close()
</code></pre>
<p>更好的写法可以先判断cude是否可用在决定是否转到cude中</p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1673061721768-4f7868b9-39c5-4815-a1bd-aaa93fe389bb.png" class title="img">

<h2 id="使用GPU训练（二）"><a href="#使用GPU训练（二）" class="headerlink" title="使用GPU训练（二）"></a>使用GPU训练（二）</h2><p>用.to指定训练的设备</p>
<img src="/2023/03/28/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1673062711005-a3fab286-5149-4cb0-ae9f-e2adbf9386ed.png" class title="img">

<p>在方法一的位置替换to</p>
<p>GPU可用就用cuda 不可用就用cpu</p>
<pre><code class="python">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() alse &quot;cpu&quot;)
</code></pre>
<h2 id="完整的模型验证套路"><a href="#完整的模型验证套路" class="headerlink" title="完整的模型验证套路"></a>完整的模型验证套路</h2><p>利用已经训练好的模型，提供输入进行测试</p>
<p>根据模型 有的模型只能是三通道的图片需要加上</p>
<pre><code class="python">image = image.convert(&#39;RGB&#39;)
</code></pre>
<p>因为png格式为4个通道，除了RGB还有一个透明通道，所以调用<code>image=image.convert(&#39;RGB&#39;)</code>保留其他颜色通道</p>
<p>当然，如果图片本来是3个通道，经过此操作不变，加上这一步可用适应png,jpg各种格式图片。</p>
<pre><code class="python">from PIL import Image
import torchvision
from torch import nn
import torch
class CIFAR10Model(nn.Module):
    def __init__(self) -&gt; None:
        super(CIFAR10Model,self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,32,5,1,2),
            nn.MaxPool2d(2),
            nn.Conv2d(32,64,5,1,2),
            nn.MaxPool2d(2),
            nn.Flatten(),#铺平
            nn.Linear(64*4*4,64),#输入64*4*4 输出64
            nn.Linear(64,10)
        )
    def forward(self,x):
        x = self.model(x)
        return x

image_path = &quot;E:\Desktop\StudyPytorch\code\dog.png&quot;
image = Image.open(image_path)
image = image.convert(&quot;RGB&quot;)
transfrom = torchvision.transforms.Compose([torchvision.transforms.Resize((32,32)),torchvision.transforms.ToTensor()])
image = transfrom(image)
#print(image.shape)

#加载网络模型
model = torch.load(&quot;E:\Desktop\StudyPytorch\code\model_root\model_19.pth&quot;)
#指定batch
image = torch.reshape(image,(1,3,32,32))
model.eval()
with torch.no_grad():
    output = model(image)
    print(output.argmax(1))
</code></pre>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls"
                data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
            <ul id="audio-list" style="display:none">
                
            </ul>
            
                        
            
            
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d=''
        data-p='https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token'
    >Comments</div>


            
            
        </div>
        <div class="sidebar">
            <div class="box animated fadeInRight">
                <div class="subbox">
                    <img src="/img/dog.jpg" height=300 width=300></img>
                    <p>ZZH</p>
                    <span>Think like an artist, develop like an artisan</span>
                    <dl>
                        
                        
                    </dl>
                </div>
                <ul>
                    <li><a href="/">23 <p>Articles</p></a></li>
                    <li><a href="/categories">3 <p>Categories</p></a></li>
                    <li><a href="/tags">30 <p>Tags</p></a></li>
                </ul>
            </div>
            
            
            
            <div class="box sticky animated fadeInRight faster">
                <div id="toc" class="subbox">
                    <h4>Contents</h4>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Anaconda%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">Anaconda笔记</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch"><span class="toc-number">2.</span> <span class="toc-text">Pytorch</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pytorch-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.</span> <span class="toc-text">Pytorch 加载数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#dataset-%EF%BC%9A%E6%8F%90%E4%BE%9B%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E5%8E%BB%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E5%8F%8Alabel"><span class="toc-number">2.1.1.</span> <span class="toc-text">dataset ：提供一种方式去获取数据及label</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DataLoader%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.1.2.</span> <span class="toc-text">DataLoader的使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TensorBorad%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.2.</span> <span class="toc-text">TensorBorad的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#add-scalar"><span class="toc-number">2.2.1.</span> <span class="toc-text">add_scalar()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#add-image"><span class="toc-number">2.2.2.</span> <span class="toc-text">add_image()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transforms%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%88torchvision%E4%B8%AD%E7%9A%84transforms%EF%BC%89"><span class="toc-number">2.2.3.</span> <span class="toc-text">Transforms的使用（torchvision中的transforms）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84Transforms"><span class="toc-number">2.2.4.</span> <span class="toc-text">常见的Transforms</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torchvision%E4%B8%AD%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.2.5.</span> <span class="toc-text">torchvision中数据集的使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%AA%A8%E6%9E%B6-nn-Module%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.3.</span> <span class="toc-text">神经网络的基本骨架 nn.Module的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82convolution"><span class="toc-number">2.4.</span> <span class="toc-text">卷积层convolution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96"><span class="toc-number">2.5.</span> <span class="toc-text">最大池化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB"><span class="toc-number">2.6.</span> <span class="toc-text">非线性激活</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%B1%82"><span class="toc-number">2.7.</span> <span class="toc-text">线性层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sequential-%E5%BA%8F%E5%88%97"><span class="toc-number">2.8.</span> <span class="toc-text">sequential 序列</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.9.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">2.10.</span> <span class="toc-text">反向传播</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">2.11.</span> <span class="toc-text">优化器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BF%AE%E6%94%B9"><span class="toc-number">2.12.</span> <span class="toc-text">现有网络模型的使用和修改</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E6%8C%81%E4%B8%8E%E8%AF%BB%E5%8F%96"><span class="toc-number">2.13.</span> <span class="toc-text">网络模型的保持与读取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF%EF%BC%88%E4%B8%80%EF%BC%89"><span class="toc-number">2.14.</span> <span class="toc-text">完整模型训练套路（一）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF%EF%BC%88%E4%BA%8C%EF%BC%89"><span class="toc-number">2.15.</span> <span class="toc-text">完整训练套路（二）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF3"><span class="toc-number">2.16.</span> <span class="toc-text">完整的模型训练套路3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E4%B8%80%EF%BC%89"><span class="toc-number">2.17.</span> <span class="toc-text">使用GPU训练（一）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E4%BA%8C%EF%BC%89"><span class="toc-number">2.18.</span> <span class="toc-text">使用GPU训练（二）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81%E5%A5%97%E8%B7%AF"><span class="toc-number">2.19.</span> <span class="toc-text">完整的模型验证套路</span></a></li></ol></li></ol>
                </div>
            </div>
            
            
        </div>
    </div>
</div>

    </div>
</div>
    <div id="back-to-top" class="animated fadeIn faster">
        <div class="flow"></div>
        <span class="percentage animated fadeIn faster">0%</span>
        <span class="iconfont icon-top02 animated fadeIn faster"></span>
    </div>
</body>
<footer>
    <p class="copyright" id="copyright">
        &copy; 2023
        <span class="gradient-text">
            ZZH
        </span>.
        Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
        Theme
        <span class="gradient-text">
            <a href="https://github.com/TriDiamond/hexo-theme-obsidian" title="Obsidian" target="_blank" rel="noopener">Obsidian</a>
        </span>
        <small><a href="https://github.com/TriDiamond/hexo-theme-obsidian/blob/master/CHANGELOG.md" title="v1.4.9.3" target="_blank" rel="noopener">v1.4.9.3</a></small>
        
        </br>
        
        <span class="gradient-text">
            <a href="/" title="" target="_blank" rel="noopener"></a>
        </span>
        
        
        </br>
        
        <span class="gradient-text">
            <a href="/" title="" target="_blank" rel="noopener"></a>
        </span>
        
    </p>
</footer>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX", "TeX"],
      linebreaks: {
        automatic: true
      },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"]
      ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      noUndefined: {
        attributes: {
          mathcolor: "red",
          mathbackground: "#FFEEEE",
          mathsize: "90%"
        }
      },
      Macros: {
        href: "{}"
      }
    },
    messageStyle: "none"
  });
</script>
<script>
  function initialMathJax() {
    MathJax.Hub.Queue(function () {
      var all = MathJax.Hub.getAllJax(),
        i;
      // console.log(all);
      for (i = 0; i < all.length; i += 1) {
        console.log(all[i].SourceElement().parentNode)
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  }

  function reprocessMathJax() {
    if (typeof MathJax !== 'undefined') {
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    }
  }
</script>


 
<link rel="stylesheet" href="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.css">
 
<script src="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.js"></script>
  
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/obsidian.js"></script>
<script src="/js/jquery.truncate.js"></script>
<script src="/js/search.js"></script>
 
<script src="//cdn.bootcss.com/typed.js/2.0.10/typed.min.js"></script>
 
<script src="//cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script>
 
<script src="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>


<script src="https://cdn.bootcss.com/codemirror/5.48.4/codemirror.min.js"></script>
 
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/javascript/javascript.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/css/css.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/xml/xml.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/htmlmixed/htmlmixed.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/clike/clike.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/php/php.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/shell/shell.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/python/python.min.js"></script>
   
<script src="/js/busuanzi.min.js"></script>

<script>
  $(document).ready(function () {
    if ($('span[id^="busuanzi_"]').length) {
      initialBusuanzi();
    }
  });
</script>
 
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css">


<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
  

<script>
  function initialTyped() {
    var typedTextEl = $('.typed-text');
    if (typedTextEl && typedTextEl.length > 0) {
      var typed = new Typed('.typed-text', {
        strings: ['Think like an artist, develop like an artisan', '艺术家思维去思考问题，工匠创造精神去开发'],
        typeSpeed: 90,
        loop: true,
        loopCount: Infinity,
        backSpeed: 20,
      });
    }
  }

  if ($('.article-header') && $('.article-header').length) {
    $(document).ready(function () {
      initialTyped();
    });
  }
</script>




<!-- 引用依赖 -->
<script>document.write(aplayerconf)</script>




</html>
